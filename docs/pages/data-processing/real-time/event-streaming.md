# Event Streaming

---

## Table of Contents
<!-- TOC -->
* [Event Streaming](#event-streaming)
  * [Table of Contents](#table-of-contents)
  * [Key Concepts and Components](#key-concepts-and-components)
    * [Events](#events)
    * [Event Streams](#event-streams)
    * [Publish-Subscribe Model](#publish-subscribe-model)
    * [Event Brokers](#event-brokers)
    * [Event Processing](#event-processing)
    * [Fault Tolerance and Scalability](#fault-tolerance-and-scalability)
  * [Ref.](#ref)
<!-- TOC -->

Event streaming is a data processing approach that involves the _continuous and real-time transmission of data as a sequence of events_. It's a mechanism for handling and processing large volumes of data, particularly in scenarios where data is generated, ingested, and processed at high speeds. Event streaming is widely used in various applications, including real-time analytics, monitoring, and distributed systems.

## Key Concepts and Components

### Events
Events are discrete pieces of data that represent a _change in state or an occurrence in a system_. They can be as simple as a timestamp or as complex as a structured message. Events are generated by various sources, such as sensors, applications, or users.


<sub>[Back to top](#table-of-contents)</sub>

### Event Streams
Event streams are _sequences of events, typically organized chronologically_. These streams are often persisted and can be replayed for historical analysis. Event streams are durable, meaning that they retain data even if consumers are not actively processing them.


<sub>[Back to top](#table-of-contents)</sub>

### Publish-Subscribe Model
Event streaming often employs a publish-subscribe model, where producers (those generating events) publish events to specific topics or channels, and consumers (applications or services) subscribe to those topics to receive events of interest. This decouples the producers from the consumers, allowing for scalability and flexibility.


<sub>[Back to top](#table-of-contents)</sub>


### Event Brokers
Event brokers are the infrastructure components responsible for managing the distribution of events. They handle the routing, storage, and delivery of events to the appropriate consumers. Popular event brokers include Apache Kafka and Apache Pulsar.

<sub>[Back to top](#table-of-contents)</sub>

### Event Processing
Event processing involves consuming and acting upon events in real-time. Consumers can perform various tasks, such as data transformation, aggregation, filtering, and triggering actions based on event content.

<sub>[Back to top](#table-of-contents)</sub>

### Fault Tolerance and Scalability
Event streaming systems are designed to be fault-tolerant and highly scalable. They often use distributed architectures to ensure reliability and handle large workloads.


<sub>[Back to top](#table-of-contents)</sub>

---

## Ref.

- https://microservices.io/patterns/data/event-sourcing.html#:~:text=Event%20sourcing%20persists%20the%20state,operation%2C%20it%20is%20inherently%20atomic.
- https://martinfowler.com/eaaDev/EventSourcing.html

---

[Get Started](../../../get-started.md) |
[Real Time Processing](../../../get-started.md#real-time-processing)
[Data Processing](../../../get-started.md#data-processing)
___
